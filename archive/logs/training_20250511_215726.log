2025-05-11 21:57:26,259 - contrastive_training - INFO - Random seeds set for reproducibility
2025-05-11 21:57:26,259 - contrastive_training - INFO - Training parameters:
2025-05-11 21:57:26,259 - contrastive_training - INFO - Backbone architecture: resnet18
2025-05-11 21:57:26,259 - contrastive_training - INFO - Batch size: 12
2025-05-11 21:57:26,259 - contrastive_training - INFO - Embedding dimension: 128
2025-05-11 21:57:26,259 - contrastive_training - INFO - Learning rate: 0.0001
2025-05-11 21:57:26,259 - contrastive_training - INFO - Weight decay: 0.0001
2025-05-11 21:57:26,259 - contrastive_training - INFO - Max epochs: 75
2025-05-11 21:57:26,259 - contrastive_training - INFO - Early stopping patience: 15
2025-05-11 21:57:26,259 - contrastive_training - INFO - NT-Xent temperature: 0.05
2025-05-11 21:57:26,259 - contrastive_training - INFO - Hard negative weight: 0.05
2025-05-11 21:57:26,259 - contrastive_training - INFO - Mixup alpha: 0.2
2025-05-11 21:57:26,272 - contrastive_training - INFO - Using device: cuda
2025-05-11 21:57:26,272 - contrastive_training - INFO - Data path: data/csv_files/data_cleaned.csv
2025-05-11 21:57:26,272 - contrastive_training - INFO - Image folder: data/final-sample-dataset/images
2025-05-11 21:57:26,405 - contrastive_training - INFO - Dataset successfully loaded with 1166 samples
2025-05-11 21:57:26,425 - contrastive_training - INFO - Song embedding dimension: 64
2025-05-11 21:57:42,981 - contrastive_training - INFO - Train set: 816 samples
2025-05-11 21:57:42,981 - contrastive_training - INFO - Validation set: 175 samples
2025-05-11 21:57:42,981 - contrastive_training - INFO - Test set: 175 samples
2025-05-11 21:57:42,981 - contrastive_training - INFO - Actual batch sizes - Train: 12, Val: 12, Test: 12
2025-05-11 21:57:42,981 - contrastive_training - INFO - DataLoaders created successfully
2025-05-11 21:57:43,094 - contrastive_training - INFO - Model initialized successfully with resnet18 backbone
2025-05-11 21:57:43,095 - contrastive_training - INFO - Optimizer and scheduler initialized
2025-05-11 21:57:43,095 - contrastive_training - INFO - Starting training...
2025-05-11 21:57:43,179 - contrastive_training - INFO - Starting enhanced training on device: cuda
2025-05-11 21:57:43,664 - contrastive_training - ERROR - Error during training: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor []], which is output 0 of ExpBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
2025-05-11 21:57:43,664 - contrastive_training - ERROR - Stack trace:
Traceback (most recent call last):
  File "/home/asdf/ig-project/train.py", line 589, in <module>
    trained_model, history = train_contrastive_model(
  File "/home/asdf/ig-project/train.py", line 166, in train_contrastive_model
    loss.backward()
  File "/home/asdf/anaconda3/envs/project/lib/python3.10/site-packages/torch/_tensor.py", line 581, in backward
    torch.autograd.backward(
  File "/home/asdf/anaconda3/envs/project/lib/python3.10/site-packages/torch/autograd/__init__.py", line 347, in backward
    _engine_run_backward(
  File "/home/asdf/anaconda3/envs/project/lib/python3.10/site-packages/torch/autograd/graph.py", line 825, in _engine_run_backward
    return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor []], which is output 0 of ExpBackward0, is at version 1; expected version 0 instead. Hint: enable anomaly detection to find the operation that failed to compute its gradient, with torch.autograd.set_detect_anomaly(True).
