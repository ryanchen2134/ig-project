{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: essentia in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.1b6.dev1177)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (6.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# make sure to run this on virtual env with python 3.8.20\n",
    "! pip install pandas scikit-learn torch essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import essentia.standard as es\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# creating encoder class to use later\n",
    "class SongEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SongEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# after i save features from song into json, i grab specific ones to embed\n",
    "def extract_features_from_json(json_file):\n",
    "\n",
    "    # open json file\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # pick relevant features and return numpy array\n",
    "    features = [\n",
    "        data[\"lowlevel\"][\"average_loudness\"],\n",
    "        data[\"lowlevel\"][\"dissonance\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"dynamic_complexity\"],\n",
    "        data[\"lowlevel\"][\"spectral_centroid\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"spectral_flux\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"zerocrossingrate\"][\"mean\"],\n",
    "        *data[\"lowlevel\"][\"barkbands\"][\"mean\"],  \n",
    "        *data[\"lowlevel\"][\"mfcc\"][\"mean\"],     \n",
    "        data[\"rhythm\"][\"bpm\"],\n",
    "        data[\"rhythm\"][\"beats_count\"],\n",
    "        data[\"rhythm\"][\"danceability\"],\n",
    "        data[\"rhythm\"][\"onset_rate\"],\n",
    "        data[\"tonal\"][\"chords_strength\"][\"mean\"],\n",
    "        data[\"tonal\"][\"hpcp_crest\"][\"mean\"],\n",
    "        data[\"tonal\"][\"hpcp_entropy\"][\"mean\"],\n",
    "        data[\"tonal\"][\"key_edma\"][\"strength\"],\n",
    "        data[\"tonal\"][\"key_krumhansl\"][\"strength\"],\n",
    "        data[\"tonal\"][\"key_temperley\"][\"strength\"],\n",
    "        data[\"metadata\"][\"audio_properties\"][\"length\"],\n",
    "        data[\"metadata\"][\"audio_properties\"][\"sample_rate\"]\n",
    "    ]\n",
    "\n",
    "    feature_vector = np.array(features)\n",
    "    return feature_vector\n",
    "\n",
    "def save_vector_to_csv(vector, file_path):\n",
    "\n",
    "    # take the vector and save it to a csv file\n",
    "    df = pd.DataFrame([vector])\n",
    "    df.to_csv(file_path, index=False, header=False)\n",
    "    print(f\"Feature vector saved to: {file_path}\")\n",
    "\n",
    "def encode_and_save_song_vectors(csv_file, encoder):\n",
    "\n",
    "    # take the csv file with the vector in it, then encode it\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    song_vector = df.values.flatten().astype(np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_vector = encoder(torch.tensor(song_vector)).numpy()\n",
    "\n",
    "    save_vector_to_csv(encoded_vector, csv_file)\n",
    "\n",
    "def extract_encode(artist, song_name, audio_folder=\"audio\", json_folder=\"song_features\", csv_folder=\"song_csv\", encoder=None): \n",
    "    audio_file = os.path.join(audio_folder, f\"{artist} - {song_name}.wav\")\n",
    "    json_file = os.path.join(json_folder, f\"{artist} - {song_name}.json\")\n",
    "    csv_file = os.path.join(csv_folder, f\"{artist} - {song_name}.csv\")\n",
    "\n",
    "    features, _ = es.MusicExtractor(\n",
    "        lowlevelStats=['mean', 'stdev'],\n",
    "        rhythmStats=['mean', 'stdev'],\n",
    "        tonalStats=['mean', 'stdev'])(audio_file)\n",
    "\n",
    "    # features to json -> extract to feature vector -> save to csv\n",
    "    es.YamlOutput(filename=json_file, format='json')(features)\n",
    "    feature_vector = extract_features_from_json(json_file)\n",
    "    save_vector_to_csv(feature_vector, csv_file)\n",
    "\n",
    "    # encode and save to csv\n",
    "    if encoder:\n",
    "        encode_and_save_song_vectors(csv_file, encoder)\n",
    "\n",
    "def mass_encoder(csv_file, audio_folder=\"audio\", json_folder=\"song_features\", csv_folder=\"song_csv\", encoder=None):\n",
    "  \n",
    "    # read csv and check if required columns exist\n",
    "    pair_data = pd.read_csv(csv_file)\n",
    "    if not all(col in pair_data.columns for col in [\"id\", \"music_artist\", \"music_title\"]):\n",
    "        raise ValueError(\"CSV file must contain 'id', 'music_artist', and 'music_title' columns.\")\n",
    "    \n",
    "    # filter out rows with nan values in song\n",
    "    pair_data = pair_data[pair_data[\"music_artist\"].notna() & pair_data[\"music_title\"].notna()]\n",
    "\n",
    "    output_file = os.path.join(os.path.dirname(csv_file), \"pairs_songencoded.csv\")\n",
    "    output_data = []\n",
    "    \n",
    "    # tterate through each row in the CSV file\n",
    "    for index, row in pair_data.iterrows():\n",
    "        artist = row[\"music_artist\"]\n",
    "        song_name = row[\"music_title\"]\n",
    "        shortcode = row[\"shortcode\"]\n",
    "        image_link = row[\"head_image_url\"]\n",
    "\n",
    "        print(f\"Processing song {index + 1}: {artist} - {song_name}\")\n",
    "\n",
    "        try:\n",
    "            # extract features and encode the song\n",
    "            extract_encode(\n",
    "                artist=artist,\n",
    "                song_name=song_name,\n",
    "                audio_folder=audio_folder,\n",
    "                json_folder=json_folder,\n",
    "                csv_folder=csv_folder,\n",
    "                encoder=encoder\n",
    "            )\n",
    "\n",
    "            song_csv_path = os.path.join(csv_folder, f\"{artist} - {song_name}.csv\")\n",
    "            embedding_df = pd.read_csv(song_csv_path, header=None)\n",
    "            embedding_vector = embedding_df.values.flatten().tolist()\n",
    "\n",
    "            output_data.append({\n",
    "                \"shortcode\" : shortcode,\n",
    "                \"link\" : image_link,\n",
    "                \"embedding\" : embedding_vector\n",
    "            })\n",
    "\n",
    "            pd.DataFrame(output_data).to_csv(output_file, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {artist} - {song_name}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing song 1: BigXthaPlug - Mmhmm\n",
      "Feature vector saved to: song_csv/BigXthaPlug - Mmhmm.csv\n",
      "Feature vector saved to: song_csv/BigXthaPlug - Mmhmm.csv\n",
      "Processing song 2: NLE Choppa, BigXthaPlug - PISTOL PACCIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/NLE Choppa, BigXthaPlug - PISTOL PACCIN.csv\n",
      "Feature vector saved to: song_csv/NLE Choppa, BigXthaPlug - PISTOL PACCIN.csv\n",
      "Processing song 3: Sam Barber - Straight and Narrow\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Sam Barber - Straight and Narrow.csv\n",
      "Feature vector saved to: song_csv/Sam Barber - Straight and Narrow.csv\n",
      "Processing song 4: Owen Wilson - Don't Give Up On Us\n",
      "Failed to process Owen Wilson - Don't Give Up On Us: In MusicExtractor.compute: MetadataReader: File does not exist or does not seem to be of a supported filetype. AudioLoader: Could not open file \"audio/Owen Wilson - Don't Give Up On Us.wav\", error = No such file or directory\n",
      "Processing song 5: BigXthaPlug, Tommy Newport - Comes & Goes (feat. Tommy Newport)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/BigXthaPlug, Tommy Newport - Comes & Goes (feat. Tommy Newport).csv\n",
      "Feature vector saved to: song_csv/BigXthaPlug, Tommy Newport - Comes & Goes (feat. Tommy Newport).csv\n",
      "Processing song 6: Wiz Khalifa - Young, Wild & Free (feat. Bruno Mars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Wiz Khalifa - Young, Wild & Free (feat. Bruno Mars).csv\n",
      "Feature vector saved to: song_csv/Wiz Khalifa - Young, Wild & Free (feat. Bruno Mars).csv\n",
      "Processing song 7: Sam R Barber - As Time Passes\n",
      "Feature vector saved to: song_csv/Sam R Barber - As Time Passes.csv\n",
      "Feature vector saved to: song_csv/Sam R Barber - As Time Passes.csv\n",
      "Processing song 8: Billy Idol - White Wedding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Billy Idol - White Wedding.csv\n",
      "Feature vector saved to: song_csv/Billy Idol - White Wedding.csv\n",
      "Processing song 10: The Red Clay Strays - Wondering Why\n",
      "Feature vector saved to: song_csv/The Red Clay Strays - Wondering Why.csv\n",
      "Feature vector saved to: song_csv/The Red Clay Strays - Wondering Why.csv\n",
      "Processing song 11: Travis Scott - Antidote\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Travis Scott - Antidote.csv\n",
      "Feature vector saved to: song_csv/Travis Scott - Antidote.csv\n",
      "Processing song 13: George Strait - All My Ex's Live In Texas\n",
      "Failed to process George Strait - All My Ex's Live In Texas: In MusicExtractor.compute: MetadataReader: File does not exist or does not seem to be of a supported filetype. AudioLoader: Could not open file \"audio/George Strait - All My Ex's Live In Texas.wav\", error = No such file or directory\n",
      "Processing song 15: Nelly - Grillz (feat. Paul Wall, Ali & Gipp)\n",
      "Feature vector saved to: song_csv/Nelly - Grillz (feat. Paul Wall, Ali & Gipp).csv\n",
      "Feature vector saved to: song_csv/Nelly - Grillz (feat. Paul Wall, Ali & Gipp).csv\n",
      "Processing song 16: Kate Bush - Running Up That Hill (A Deal With God) [2018 Remaster]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Kate Bush - Running Up That Hill (A Deal With God) [2018 Remaster].csv\n",
      "Feature vector saved to: song_csv/Kate Bush - Running Up That Hill (A Deal With God) [2018 Remaster].csv\n",
      "Processing song 17: Billy Idol - Rebel Yell\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Billy Idol - Rebel Yell.csv\n",
      "Feature vector saved to: song_csv/Billy Idol - Rebel Yell.csv\n",
      "Processing song 18: Shaboozey - Drink Don't Need No Mix (feat. BigXthaPlug)\n",
      "Failed to process Shaboozey - Drink Don't Need No Mix (feat. BigXthaPlug): In MusicExtractor.compute: MetadataReader: File does not exist or does not seem to be of a supported filetype. AudioLoader: Could not open file \"audio/Shaboozey - Drink Don't Need No Mix (feat. BigXthaPlug).wav\", error = No such file or directory\n",
      "Processing song 19: Tommy Richman - ACTIN UP\n",
      "Feature vector saved to: song_csv/Tommy Richman - ACTIN UP.csv\n",
      "Feature vector saved to: song_csv/Tommy Richman - ACTIN UP.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # path to csv\n",
    "    csv_file = \"meowmeow.csv\" \n",
    "\n",
    "    input_dim = 58 \n",
    "    hidden_dim = 128\n",
    "    output_dim = 64\n",
    "    encoder = SongEncoder(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    # idk wtf this does lol\n",
    "    model_path = \"song_encoder.pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        encoder.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Loaded pre-trained encoder from {model_path}\")\n",
    "\n",
    "    # use goat function and boom boom done (make sure to download songs in spotdl.ipynb first)\n",
    "    mass_encoder(csv_file=csv_file, encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
