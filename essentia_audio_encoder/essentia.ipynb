{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (1.3.2)\n",
      "Requirement already satisfied: torch in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.4.1)\n",
      "Requirement already satisfied: essentia in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.1b6.dev1177)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (6.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# make sure to run this on virtual env with python 3.8.20\n",
    "! pip install pandas scikit-learn torch essentia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import essentia.standard as es\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "# creating encoder class to use later\n",
    "class SongEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SongEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.relu = nn.GELU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# after i save features from song into json, i grab specific ones to embed\n",
    "def extract_features_from_json(json_file):\n",
    "\n",
    "    # open json file\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # pick relevant features and return numpy array\n",
    "    features = [\n",
    "        data[\"lowlevel\"][\"average_loudness\"],\n",
    "        data[\"lowlevel\"][\"dissonance\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"dynamic_complexity\"],\n",
    "        data[\"lowlevel\"][\"spectral_centroid\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"spectral_flux\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"zerocrossingrate\"][\"mean\"],\n",
    "        *data[\"lowlevel\"][\"barkbands\"][\"mean\"],  \n",
    "        *data[\"lowlevel\"][\"mfcc\"][\"mean\"],     \n",
    "        data[\"rhythm\"][\"bpm\"],\n",
    "        data[\"rhythm\"][\"beats_count\"],\n",
    "        data[\"rhythm\"][\"danceability\"],\n",
    "        data[\"rhythm\"][\"onset_rate\"],\n",
    "        data[\"tonal\"][\"chords_strength\"][\"mean\"],\n",
    "        data[\"tonal\"][\"hpcp_crest\"][\"mean\"],\n",
    "        data[\"tonal\"][\"hpcp_entropy\"][\"mean\"],\n",
    "        data[\"tonal\"][\"key_edma\"][\"strength\"],\n",
    "        data[\"tonal\"][\"key_krumhansl\"][\"strength\"],\n",
    "        data[\"tonal\"][\"key_temperley\"][\"strength\"],\n",
    "        data[\"metadata\"][\"audio_properties\"][\"length\"],\n",
    "        data[\"metadata\"][\"audio_properties\"][\"sample_rate\"]\n",
    "    ]\n",
    "\n",
    "    feature_vector = np.array(features)\n",
    "    return feature_vector\n",
    "\n",
    "def save_vector_to_csv(vector, file_path):\n",
    "\n",
    "    # take the vector and save it to a csv file\n",
    "    df = pd.DataFrame([vector])\n",
    "    df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "    # also save it to song_vector to check\n",
    "    vector_csv = os.path.join(\"song_vector\", f\"{artist} - {song_name}.csv\")\n",
    "    df.to_csv(vector_csv, index=False, header=False)\n",
    "\n",
    "    print(f\"Feature vector saved to: {file_path}\")\n",
    "\n",
    "def encode_and_save_song_vectors(csv_file, encoder):\n",
    "\n",
    "    # take the csv file with the vector in it, then encode it\n",
    "    df = pd.read_csv(csv_file, header=None)\n",
    "    song_vector = df.values.flatten().astype(np.float32)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        encoded_vector = encoder(torch.tensor(song_vector)).numpy()\n",
    "\n",
    "    save_vector_to_csv(encoded_vector, csv_file)\n",
    "\n",
    "def extract_encode(artist, song_name, audio_folder=\"audio\", json_folder=\"song_features\", csv_folder=\"song_csv\", encoder=None): \n",
    "    audio_file = os.path.join(audio_folder, f\"{artist} - {song_name}.wav\")\n",
    "    json_file = os.path.join(json_folder, f\"{artist} - {song_name}.json\")\n",
    "    csv_file = os.path.join(csv_folder, f\"{artist} - {song_name}.csv\")\n",
    "\n",
    "    features, _ = es.MusicExtractor(\n",
    "        lowlevelStats=['mean', 'stdev'],\n",
    "        rhythmStats=['mean', 'stdev'],\n",
    "        tonalStats=['mean', 'stdev'])(audio_file)\n",
    "\n",
    "    # features to json -> extract to feature vector -> save to csv\n",
    "    es.YamlOutput(filename=json_file, format='json')(features)\n",
    "    feature_vector = extract_features_from_json(json_file)\n",
    "    save_vector_to_csv(feature_vector, csv_file)\n",
    "\n",
    "    # encode and save to csv\n",
    "    if encoder:\n",
    "        encode_and_save_song_vectors(csv_file, encoder)\n",
    "\n",
    "def mass_encoder(csv_file, audio_folder=\"audio\", json_folder=\"song_features\", csv_folder=\"song_csv\", encoder=None):\n",
    "  \n",
    "    # read csv and check if required columns exist\n",
    "    pair_data = pd.read_csv(csv_file)\n",
    "    if not all(col in pair_data.columns for col in [\"id\", \"music_artist\", \"music_title\"]):\n",
    "        raise ValueError(\"CSV file must contain 'id', 'music_artist', and 'music_title' columns.\")\n",
    "    \n",
    "    # filter out rows with nan values in song\n",
    "    pair_data = pair_data[pair_data[\"music_artist\"].notna() & pair_data[\"music_title\"].notna()]\n",
    "\n",
    "    output_file = os.path.join(os.path.dirname(csv_file), \"pairs_songencoded.csv\")\n",
    "    output_data = []\n",
    "    \n",
    "    # tterate through each row in the CSV file\n",
    "    for index, row in pair_data.iterrows():\n",
    "\n",
    "        artist = row[\"music_artist\"]\n",
    "        print(artist)\n",
    "        song_name = row[\"music_title\"]\n",
    "        print(song_name)\n",
    "        shortcode = row[\"shortcode\"]\n",
    "        image_link = row[\"head_image_url\"]\n",
    "\n",
    "        print(f\"Processing song {index + 1}: {artist} - {song_name}\")\n",
    "\n",
    "        try:\n",
    "            # extract features and encode the song\n",
    "            extract_encode(\n",
    "                artist=artist,\n",
    "                song_name=song_name,\n",
    "                audio_folder=audio_folder,\n",
    "                json_folder=json_folder,\n",
    "                csv_folder=csv_folder,\n",
    "                encoder=encoder\n",
    "            )\n",
    "\n",
    "            song_csv_path = os.path.join(csv_folder, f\"{artist} - {song_name}.csv\")\n",
    "            embedding_df = pd.read_csv(song_csv_path, header=None)\n",
    "            embedding_vector = embedding_df.values.flatten().tolist()\n",
    "\n",
    "            output_data.append({\n",
    "                \"shortcode\" : shortcode,\n",
    "                \"link\" : image_link,\n",
    "                \"embedding\" : embedding_vector\n",
    "            })\n",
    "\n",
    "            pd.DataFrame(output_data).to_csv(output_file, index=False)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {artist} - {song_name}: {e}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing song 1: BigXthaPlug - Mmhmm\n",
      "Failed to process BigXthaPlug - Mmhmm: name 'artist' is not defined\n",
      "Processing song 2: NLE Choppa, BigXthaPlug - PISTOL PACCIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process NLE Choppa, BigXthaPlug - PISTOL PACCIN: name 'artist' is not defined\n",
      "Processing song 3: Sam Barber - Straight and Narrow\n",
      "Failed to process Sam Barber - Straight and Narrow: name 'artist' is not defined\n",
      "Processing song 4: Owen Wilson - Dont Give Up On Us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process Owen Wilson - Dont Give Up On Us: name 'artist' is not defined\n",
      "Processing song 5: BigXthaPlug, Tommy Newport - Comes & Goes (feat. Tommy Newport)\n",
      "Failed to process BigXthaPlug, Tommy Newport - Comes & Goes (feat. Tommy Newport): name 'artist' is not defined\n",
      "Processing song 6: Wiz Khalifa - Young, Wild & Free (feat. Bruno Mars)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n",
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process Wiz Khalifa - Young, Wild & Free (feat. Bruno Mars): name 'artist' is not defined\n",
      "Processing song 7: Sam R Barber - As Time Passes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded pre-trained encoder from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# use goat function and boom boom done (make sure to download songs in spotdl.ipynb first)\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[43mmass_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 125\u001b[0m, in \u001b[0;36mmass_encoder\u001b[0;34m(csv_file, audio_folder, json_folder, csv_folder, encoder)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing song \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msong_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;66;03m# extract features and encode the song\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[43mextract_encode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43martist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m        \u001b[49m\u001b[43msong_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msong_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43maudio_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maudio_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcsv_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcsv_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m     song_csv_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msong_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m     embedding_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(song_csv_path, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[23], line 87\u001b[0m, in \u001b[0;36mextract_encode\u001b[0;34m(artist, song_name, audio_folder, json_folder, csv_folder, encoder)\u001b[0m\n\u001b[1;32m     84\u001b[0m json_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(json_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msong_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     85\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(csv_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00martist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msong_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 87\u001b[0m features, _ \u001b[38;5;241m=\u001b[39m \u001b[43mes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMusicExtractor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlowlevelStats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstdev\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrhythmStats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstdev\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtonalStats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstdev\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# features to json -> extract to feature vector -> save to csv\u001b[39;00m\n\u001b[1;32m     93\u001b[0m es\u001b[38;5;241m.\u001b[39mYamlOutput(filename\u001b[38;5;241m=\u001b[39mjson_file, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m'\u001b[39m)(features)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.8/site-packages/essentia/standard.py:123\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ai/lib/python3.8/site-packages/essentia/standard.py:104\u001b[0m, in \u001b[0;36m_create_essentia_class.<locals>.Algo.compute\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError cannot convert argument \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \\\n\u001b[1;32m    100\u001b[0m               \u001b[38;5;241m%\u001b[39m(\u001b[38;5;28mstr\u001b[39m(_c\u001b[38;5;241m.\u001b[39mdetermineEdt(arg)), \u001b[38;5;28mstr\u001b[39m(goalType)))\n\u001b[1;32m    102\u001b[0m     convertedArgs\u001b[38;5;241m.\u001b[39mappend(convertedData)\n\u001b[0;32m--> 104\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__compute__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconvertedArgs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# we have to make an exceptional case for YamlInput, because we need\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# to wrap the Pool that it outputs w/ our python Pool from common.py\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYamlInput\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPoolAggregator\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSvmClassifier\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPCA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGaiaTransform\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExtractor\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTensorflowPredict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # path to csv\n",
    "    csv_file = \"meowmeow.csv\" \n",
    "\n",
    "    input_dim = 58 \n",
    "    hidden_dim = 128\n",
    "    output_dim = 128\n",
    "    encoder = SongEncoder(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "    # idk wtf this does lol\n",
    "    model_path = \"song_encoder.pth\"\n",
    "    if os.path.exists(model_path):\n",
    "        encoder.load_state_dict(torch.load(model_path))\n",
    "        print(f\"Loaded pre-trained encoder from {model_path}\")\n",
    "\n",
    "    # use goat function and boom boom done (make sure to download songs in spotdl.ipynb first)\n",
    "    mass_encoder(csv_file=csv_file, encoder=encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
