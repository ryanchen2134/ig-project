{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: playwright in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (1.51.0)\n",
      "Requirement already satisfied: pandas in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (2.2.3)\n",
      "Requirement already satisfied: python-dotenv in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (1.1.0)\n",
      "Requirement already satisfied: pyee<13,>=12 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from playwright) (12.1.1)\n",
      "Requirement already satisfied: greenlet<4.0.0,>=3.1.1 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from playwright) (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from pandas) (2.2.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: typing-extensions in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from pyee<13,>=12->playwright) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/asdf/anaconda3/envs/basic-venv/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install playwright pandas python-dotenv\n",
    "!python3 -m playwright install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python3: can't open file '/home/asdf/ig-project/ig_scraperv3/install': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!python3 install playwright pandas python-dotenv\n",
    "!playwright install\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from playwright.async_api import async_playwright, TimeoutError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "username = os.getenv(\"USERNAME\")\n",
    "password = os.getenv(\"PASSWORD\")\n",
    "\n",
    "# Define login function\n",
    "async def signon(page, username, password):\n",
    "    try:\n",
    "        await page.goto(\"https://www.instagram.com/accounts/login/\", wait_until=\"networkidle\")\n",
    "        await page.wait_for_selector('input[name=\"username\"]', timeout=10000)\n",
    "        await page.fill('input[name=\"username\"]', username)\n",
    "        await page.fill('input[name=\"password\"]', password)\n",
    "        await page.wait_for_timeout(500)\n",
    "        print(\"Hitting login button\")\n",
    "\n",
    "        # Wait until the element with the aria-label \"Log in\" is visible.\n",
    "        await page.wait_for_selector(\"div[aria-label='Log in']\", state=\"visible\")\n",
    "        # Now attempt a click on it.\n",
    "        await page.click(\"div[aria-label='Log in']\")\n",
    "\n",
    "        #wait for networkidle\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "        \n",
    "        #look for this: <span class=\"x1lliihq x193iq5w x6ikm8r x10wlt62 xlyipyv xuxw1ft\">Save info</span>\n",
    "        # the button is its 5th parent\n",
    "        await page.wait_for_selector(\"span:has-text('Save info')\", timeout=15000)\n",
    "        # Click the button\n",
    "        await page.click(\"span:has-text('Save info')\", timeout=5000)\n",
    "        #wait for networkidle\n",
    "        await page.wait_for_load_state(\"networkidle\")\n",
    "        if \"login\" in page.url:\n",
    "            raise ValueError(\"Login failed: Incorrect username or password.\")\n",
    "        print(\"‚úÖ Successfully logged in\")\n",
    "    except TimeoutError:\n",
    "        raise TimeoutError(\"Login timed out. Check credentials or network connection.\")\n",
    "\n",
    "# Define helper to get total posts\n",
    "async def get_total_posts(page):\n",
    "    total_posts = await page.evaluate(\"\"\"\n",
    "        () => {\n",
    "            const element = document.querySelector('header section ul li span');\n",
    "            return element ? parseInt(element.innerText.replace(',', '')) : null;\n",
    "        }\n",
    "    \"\"\")\n",
    "    return total_posts if total_posts is not None else float('inf')\n",
    "\n",
    "# Modified scrape_instagram_posts to stop when a post is older than Jan 1, 2023\n",
    "async def scrape_instagram_posts(userhandle: str, max_posts: int, context, page):\n",
    "    profile_url = f\"https://www.instagram.com/{userhandle}/\"\n",
    "    await page.goto(profile_url)\n",
    "    await page.wait_for_load_state(\"networkidle\")\n",
    "\n",
    "    total_posts = await get_total_posts(page)\n",
    "    scrape_limit = min(max_posts, total_posts)\n",
    "    print(f\"üîé {userhandle}: Total posts {total_posts}, scraping up to {scrape_limit}...\")\n",
    "\n",
    "    unique_posts = {}\n",
    "    scroll_attempts = 0\n",
    "    MAX_SCROLL_ATTEMPTS = 20\n",
    "\n",
    "    while len(unique_posts) < scrape_limit and scroll_attempts < MAX_SCROLL_ATTEMPTS:\n",
    "        candidate_elements = await page.query_selector_all(\"a:has(div._aagu)\")\n",
    "        for element in candidate_elements:\n",
    "            href = await element.get_attribute(\"href\")\n",
    "            if href and \"/p/\" in href and href not in unique_posts:\n",
    "                unique_posts[href] = None\n",
    "\n",
    "        # Break early if it seems we've hit the end of the user's posts\n",
    "        new_total = len(candidate_elements)\n",
    "        if new_total == 0 or len(unique_posts) >= total_posts:\n",
    "            print(\"üìâ Reached end of available posts.\")\n",
    "            break\n",
    "\n",
    "        print(f\"üîÑ Scrolled {scroll_attempts + 1}x ‚Äî Collected: {len(unique_posts)}\")\n",
    "        if len(unique_posts) >= scrape_limit:\n",
    "            break\n",
    "        await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        await asyncio.sleep(1.5)\n",
    "        scroll_attempts += 1\n",
    "\n",
    "\n",
    "    post_hrefs = list(unique_posts.keys())[:scrape_limit]\n",
    "    results = {}\n",
    "\n",
    "    CUTOFF_DATE = datetime(2023, 1, 1)\n",
    "    print(f\"üìù Intercepting posts (cutoff: {CUTOFF_DATE.date()})...\")\n",
    "\n",
    "    for i, href in enumerate(post_hrefs, start=1):\n",
    "        post_url = f\"https://www.instagram.com{href}\"\n",
    "        new_page = await context.new_page()\n",
    "        try:\n",
    "            async with new_page.expect_response(\n",
    "                lambda response: \"/api/v1/media/\" in response.url and \"/info/\" in response.url,\n",
    "                timeout=5000\n",
    "            ) as response_info:\n",
    "                await new_page.goto(post_url)\n",
    "\n",
    "            response = await response_info.value\n",
    "            data = await response.json()\n",
    "\n",
    "            # Check the post timestamp\n",
    "            timestamp = data.get(\"items\", [{}])[0].get(\"taken_at\")\n",
    "            if timestamp:\n",
    "                post_date = datetime.fromtimestamp(timestamp)\n",
    "                if post_date < CUTOFF_DATE:\n",
    "                    print(f\"üõë Post {href} is from {post_date.date()}, before 2023. Stopping.\")\n",
    "                    await new_page.close()\n",
    "                    break\n",
    "\n",
    "            results[href] = data\n",
    "            print(f\"‚úÖ ({i}/{len(post_hrefs)}) {href} ‚Äî {post_date.date()}\")\n",
    "\n",
    "        except TimeoutError:\n",
    "            print(f\"‚è±Ô∏è Timeout: {href}\")\n",
    "        finally:\n",
    "            await new_page.close()\n",
    "\n",
    "    return results\n",
    "\n",
    "# Batch scrape users from a CSV and save to JSON\n",
    "async def scrape_users_from_csv(csv_path: str, max_posts_per_user: int, output_json: str):\n",
    "    df = pd.read_csv(csv_path, header=None)\n",
    "    usernames = df[0].dropna().unique().tolist()\n",
    "\n",
    "    if os.path.exists(output_json):\n",
    "        with open(output_json, 'r') as f:\n",
    "            all_results = json.load(f)\n",
    "    else:\n",
    "        all_results = {}\n",
    "\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=False)\n",
    "        device = p.devices[\"Pixel 5\"]\n",
    "        context = await browser.new_context(**device)\n",
    "        page = await context.new_page()\n",
    "\n",
    "        if os.path.exists(\"cookies.json\"):\n",
    "            print(\"üîÑ Loading cookies...\")\n",
    "            with open(\".cookies.json\", \"r\") as f:\n",
    "                cookies = json.load(f)\n",
    "            await context.add_cookies(cookies)\n",
    "        else:\n",
    "            print(\"üîê Logging in...\")\n",
    "            await signon(page, username, password)\n",
    "            cookies = await context.cookies()\n",
    "            with open(\".cookies.json\", \"w\") as f:\n",
    "                json.dump(cookies, f)\n",
    "\n",
    "        for user in usernames:\n",
    "            if user in all_results:\n",
    "                print(f\"‚è© Skipping {user} (already scraped)\")\n",
    "                continue\n",
    "            try:\n",
    "                result = await scrape_instagram_posts(user, max_posts_per_user, context, page)\n",
    "                all_results[user] = result\n",
    "                with open(output_json, 'w') as f:\n",
    "                    json.dump(all_results, f, indent=2)\n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Error scraping {user}: {e}\")\n",
    "\n",
    "        await browser.close()\n",
    "        print(f\"\\n‚úÖ All scraping complete. Results saved to {output_json}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscrape_users_from_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43musernames.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_posts_per_user\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_json\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mall_instagram_data.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/basic-venv/lib/python3.13/asyncio/runners.py:191\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(main, debug, loop_factory)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[32m    162\u001b[39m \n\u001b[32m    163\u001b[39m \u001b[33;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    187\u001b[39m \u001b[33;03m    asyncio.run(main())\u001b[39;00m\n\u001b[32m    188\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    189\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m events._get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    190\u001b[39m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    192\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug=debug, loop_factory=loop_factory) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m runner.run(main)\n",
      "\u001b[31mRuntimeError\u001b[39m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(scrape_users_from_csv(\"csv/usernames.csv\", max_posts_per_user=150, output_json=\"json/all_instagram_data.json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basic-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
