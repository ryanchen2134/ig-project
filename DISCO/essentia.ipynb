{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: essentia in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.1b6.dev1177)\n",
      "Requirement already satisfied: pandas in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (2.0.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (1.24.4)\n",
      "Requirement already satisfied: six in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (1.16.0)\n",
      "Requirement already satisfied: pyyaml in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from essentia) (6.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/envs/ai/lib/python3.8/site-packages (from pandas) (2025.1)\n",
      "Collecting scipy>=1.5.0 (from scikit-learn)\n",
      "  Downloading scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl.metadata (53 kB)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.3.2 scipy-1.10.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "! pip install essentia pandas scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import essentia.standard as es\n",
    "from tempfile import TemporaryDirectory\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_features_from_json(json_file):\n",
    "    \"\"\"\n",
    "    Extracts relevant features from a JSON file and returns a feature vector.\n",
    "    \"\"\"\n",
    "    with open(json_file, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    # Extract relevant features\n",
    "    features = [\n",
    "        data[\"lowlevel\"][\"average_loudness\"],\n",
    "        data[\"lowlevel\"][\"dissonance\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"dynamic_complexity\"],\n",
    "        data[\"lowlevel\"][\"spectral_centroid\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"spectral_flux\"][\"mean\"],\n",
    "        data[\"lowlevel\"][\"zerocrossingrate\"][\"mean\"],\n",
    "        *data[\"lowlevel\"][\"barkbands\"][\"mean\"],  # Flatten barkbands\n",
    "        *data[\"lowlevel\"][\"mfcc\"][\"mean\"],      # Flatten MFCCs\n",
    "        data[\"rhythm\"][\"bpm\"],\n",
    "        data[\"rhythm\"][\"beats_count\"],\n",
    "        data[\"rhythm\"][\"danceability\"],\n",
    "        data[\"rhythm\"][\"onset_rate\"],\n",
    "        data[\"tonal\"][\"chords_strength\"][\"mean\"],\n",
    "        data[\"tonal\"][\"hpcp_crest\"][\"mean\"],\n",
    "        data[\"tonal\"][\"hpcp_entropy\"][\"mean\"],\n",
    "        data[\"tonal\"][\"key_edma\"][\"strength\"],\n",
    "        data[\"tonal\"][\"key_krumhansl\"][\"strength\"],\n",
    "        data[\"tonal\"][\"key_temperley\"][\"strength\"],\n",
    "        data[\"metadata\"][\"audio_properties\"][\"length\"],\n",
    "        data[\"metadata\"][\"audio_properties\"][\"sample_rate\"]\n",
    "    ]\n",
    "\n",
    "    # Convert to a numpy array\n",
    "    feature_vector = np.array(features)\n",
    "    return feature_vector\n",
    "\n",
    "def save_vector_to_csv(vector, artist, song_name, output_folder=\"song_csv\"):\n",
    "    \"\"\"\n",
    "    Saves the feature vector to a CSV file in the specified output folder.\n",
    "    \"\"\"\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Define the CSV file path\n",
    "    csv_file = os.path.join(output_folder, f\"{artist}-{song_name}.csv\")\n",
    "\n",
    "    # Define column names\n",
    "    column_names = [\n",
    "        \"average_loudness\",\n",
    "        \"dissonance_mean\",\n",
    "        \"dynamic_complexity\",\n",
    "        \"spectral_centroid_mean\",\n",
    "        \"spectral_flux_mean\",\n",
    "        \"zerocrossingrate_mean\",\n",
    "        *[f\"barkbands_mean_{i}\" for i in range(len(vector) - 12)],  # Dynamic column names for barkbands\n",
    "        *[f\"mfcc_mean_{i}\" for i in range(13)],  # Dynamic column names for MFCCs\n",
    "        \"bpm\",\n",
    "        \"beats_count\",\n",
    "        \"danceability\",\n",
    "        \"onset_rate\",\n",
    "        \"chords_strength_mean\",\n",
    "        \"hpcp_crest_mean\",\n",
    "        \"hpcp_entropy_mean\",\n",
    "        \"key_edma_strength\",\n",
    "        \"key_krumhansl_strength\",\n",
    "        \"key_temperley_strength\",\n",
    "        \"audio_length\",\n",
    "        \"sample_rate\"]\n",
    "\n",
    "    # Save the vector to a CSV file\n",
    "    df = pd.DataFrame([vector])\n",
    "    df.to_csv(csv_file, index=False, header=False)\n",
    "    print(f\"Feature vector saved to: {csv_file}\")\n",
    "\n",
    "def download_and_extract_song(artist, song_name, audio_folder=\"audio\", csv_folder=\"song_csv\", json_folder=\"song_features\"):\n",
    "    \"\"\"\n",
    "    Downloads a song, extracts features, and saves the feature vector to a CSV file.\n",
    "    \"\"\"\n",
    "    # Ensure audio folder exists\n",
    "    os.makedirs(audio_folder, exist_ok=True)\n",
    "\n",
    "    # Format the audio file path\n",
    "    audio_file = os.path.join(audio_folder, f\"{artist}-{song_name}.wav\")\n",
    "\n",
    "    if not os.path.exists(audio_file):\n",
    "        # If file doesn't exist, download the song using spotdl\n",
    "        os.system(f\"spotdl download '{artist}-{song_name}' --format wav --output '{audio_folder}/'\")\n",
    "\n",
    "        # Rename the downloaded file\n",
    "        downloaded_files = [f for f in os.listdir(audio_folder) if f.endswith(\".wav\")]\n",
    "        if downloaded_files:\n",
    "            downloaded_file = os.path.join(audio_folder, downloaded_files[0])\n",
    "            os.rename(downloaded_file, audio_file)\n",
    "\n",
    "    # Check if file was downloaded\n",
    "    if not os.path.exists(audio_file):\n",
    "        raise FileNotFoundError(f\"Failed to download or locate audio file: {audio_file}\")\n",
    "\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(json_folder, exist_ok=True)\n",
    "\n",
    "    # Define results file per song\n",
    "    results_file = os.path.join(json_folder, f\"{artist}-{song_name}.json\")\n",
    "\n",
    "    # Extract features using Essentia\n",
    "    features, features_frames = es.MusicExtractor(\n",
    "        lowlevelStats=['mean', 'stdev'],\n",
    "        rhythmStats=['mean', 'stdev'],\n",
    "        tonalStats=['mean', 'stdev'])(audio_file)\n",
    "\n",
    "    # Save features to JSON\n",
    "    es.YamlOutput(filename=results_file, format='json')(features)\n",
    "\n",
    "    # Extract the feature vector from the JSON file\n",
    "    feature_vector = extract_features_from_json(results_file)\n",
    "\n",
    "    # Save the feature vector to a CSV file\n",
    "    save_vector_to_csv(feature_vector, artist, song_name, csv_folder)\n",
    "\n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature vector saved to: song_csv/Lady Gaga-Die with a smile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[   INFO   ] MusicExtractor: Read metadata\n",
      "[   INFO   ] MusicExtractor: Compute md5 audio hash, codec, length, and EBU 128 loudness\n",
      "[   INFO   ] MusicExtractor: Replay gain\n",
      "[   INFO   ] MusicExtractor: Compute audio features\n",
      "[   INFO   ] MusicExtractor: Compute aggregation\n",
      "[   INFO   ] All done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 7.30834842e-01,  4.52379614e-01,  5.38787127e+00,  1.24243188e+03,\n",
       "        7.33930096e-02,  5.87083884e-02,  1.53934699e-04,  5.63180121e-03,\n",
       "        1.47339527e-03,  9.94074158e-04,  1.71319197e-03,  9.13803757e-04,\n",
       "        1.22330233e-03,  1.40704459e-03,  2.18217052e-03,  2.93917139e-03,\n",
       "        1.33293727e-03,  1.79947854e-03,  1.37360161e-03,  8.91951087e-04,\n",
       "        3.52101517e-04,  2.92371609e-04,  1.96150533e-04,  1.77090697e-04,\n",
       "        1.41186450e-04,  1.90200153e-04,  1.16518997e-04,  1.21458412e-04,\n",
       "        1.07300621e-04,  9.79163306e-05,  8.01134520e-05,  2.66523875e-05,\n",
       "        5.63931735e-06, -6.83442871e+02,  1.28028030e+02, -1.28423948e+01,\n",
       "       -7.30077386e-01, -6.79468918e+00, -2.13659763e+00,  7.77765393e-01,\n",
       "        4.36371088e+00, -7.12822616e-01,  3.10417652e+00, -7.53850350e-03,\n",
       "       -2.64036727e+00, -3.01365876e+00,  1.05055832e+02,  5.39000000e+02,\n",
       "        1.04016268e+00,  3.17862582e+00,  5.28761566e-01,  1.49700432e+01,\n",
       "        1.75616884e+00,  6.87550843e-01,  6.97248638e-01,  7.08123028e-01,\n",
       "        2.51667603e+02,  4.80000000e+04])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_and_extract_song('Lady Gaga', 'Die with a smile')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
